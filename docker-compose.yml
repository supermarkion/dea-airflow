---
version: '3.7'
services:
  postgres:
    image: postgres:12
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - pgdata:/var/lib/postgresql/data/pgdata
    logging:
      options:
        max-size: 10m
        max-file: "3"
  setup-airflow:
    image: &image apache/airflow:2.1.2
    #    image: &image apache/airflow:v1-10-test-python3.8-ci
    depends_on:
      - postgres
    environment: &env
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres/airflow
      # Uncomment and add fernet key to encrypt/decrypt secrets. For details see
      # https://airflow.readthedocs.io/en/stable/howto/secure-connections.html
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__SMTP__SMTP_HOST=maildev
      - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=False
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__WEBSERVER__RBAC=True
      # Default Connections Used in the DEA Airflow deployment
      - AIRFLOW_CONN_LPGS_GADI=ssh://foo:bar@gadi.nci.org.au/
      - AIRFLOW_CONN_DEA_PUBLIC_DATA_UPLOAD=s3://foo:bar@dea-public-data-dev/
      - AIRFLOW_CONN_AWS_NCI_DB_BACKUP=s3://foo:bar@dea-db-backups/
      - HOST_USER_ID=${UID}
      - HOST_GROUP_ID=${GID}
    command: bash -c 'airflow db upgrade; airflow users create -e airflow@localhost -f Airflow -l None -p airflow -r Admin -u airflow'
  webserver:
    image: *image
    restart: always
    depends_on:
      - postgres
      - setup-airflow
    environment: *env
    logging:
      options:
        max-size: 10m
        max-file: "3"
    volumes: &volumes
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - logs/:/opt/airflow/logs
      - ./requirements.txt:/opt/airflow/requirements.txt
      - /dev/urandom:/dev/random   # Required to get non-blocking entropy source
    ports:
      - "8080:8080"
        #    command: webserver
    command: bash -c 'pip install -r /opt/airflow/requirements.txt; airflow webserver'
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
  scheduler:
    image: *image
    restart: always
    depends_on:
      - postgres
      - setup-airflow
    environment: *env
    logging:
      options:
        max-size: 10m
        max-file: "3"
    volumes: *volumes
    #    command: scheduler
    command: bash -c 'pip install -r /opt/airflow/requirements.txt; airflow scheduler'
    ports:
      - "8793:8793"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-scheduler.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
  maildev:
    image: maildev/maildev
    ports:
      - "1080:80"
volumes:
  pgdata:
  logs:
